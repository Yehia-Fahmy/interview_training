# ML Concepts Reference

Key concepts for the Data/ML Coding interview.

## Model Evaluation

- **Metrics**: Accuracy, Precision, Recall, F1, ROC-AUC
- **Cross-validation**: K-fold, stratified
- **Holdout sets**: Train/validation/test splits

## Production ML

- **Model Lifecycle**: Training → Validation → Deployment → Monitoring
- **Model Versioning**: Track versions, rollback capability
- **A/B Testing**: Statistical significance, sample sizes
- **Monitoring**: Drift detection, performance tracking

## LLM Evaluation (8090 Focus)

- **BLEU**: N-gram overlap
- **ROUGE**: Recall-oriented metrics
- **Perplexity**: Language model quality
- **Semantic Similarity**: Embedding-based evaluation
- **Task-specific**: Classification accuracy, etc.

## Feature Engineering

- **Missing Values**: Imputation strategies
- **Categorical Encoding**: One-hot, label encoding, embeddings
- **Scaling**: Standardization, normalization
- **Feature Selection**: Correlation, importance-based

## MLOps

- **Experiment Tracking**: MLflow, Weights & Biases
- **Model Registry**: Centralized model storage
- **Feature Stores**: Online and offline features
- **Model Serving**: APIs, batching, optimization

